{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import unicodedata\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/NepaliTaggedCorpus/new_submissions_parallel_corpus_project_Nepal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open(path+'/'+'processed_tag', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pickle.load(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[६१,  वर्षीय,  पियरे,  भिन्केन,  नोभेम्बर,  २९...</td>\n",
       "      <td>[&lt;CD&gt;, &lt;JJ&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;CD&gt;, &lt;POP&gt;,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[श्री,  भिन्केन,  डच,  प्रकाशन,  समूह,  एल्सेभ...</td>\n",
       "      <td>[&lt;NN&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;NN&gt;, &lt;NN&gt;, &lt;NNP&gt;, &lt;FB&gt;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[कन्सोलिडेटिड,  गोल्ड,  फिल्ड्स,  पीएलसी, का, ...</td>\n",
       "      <td>[&lt;NNP&gt;, &lt;NN&gt;, &lt;NN&gt;, &lt;NNP&gt;, &lt;PKO&gt;, &lt;JJ&gt;, &lt;NN&gt;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[एकताका,  केन्ट,  चुरोट, को,  फिल्टर,  बनाउन, ...</td>\n",
       "      <td>[&lt;RBO&gt;, &lt;NNP&gt;, &lt;NN&gt;, &lt;PKO&gt;, &lt;NN&gt;, &lt;VBI&gt;, &lt;NN&gt;,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[यस, सँग, को,  छोटो,  सम्पर्क, बाट,  मात्र,  प...</td>\n",
       "      <td>[&lt;DUM&gt;, &lt;POP&gt;, &lt;PKO&gt;, &lt;JJM&gt;, &lt;NN&gt;, &lt;POP&gt;, &lt;RP&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [६१,  वर्षीय,  पियरे,  भिन्केन,  नोभेम्बर,  २९...   \n",
       "1  [श्री,  भिन्केन,  डच,  प्रकाशन,  समूह,  एल्सेभ...   \n",
       "2  [कन्सोलिडेटिड,  गोल्ड,  फिल्ड्स,  पीएलसी, का, ...   \n",
       "3  [एकताका,  केन्ट,  चुरोट, को,  फिल्टर,  बनाउन, ...   \n",
       "4  [यस, सँग, को,  छोटो,  सम्पर्क, बाट,  मात्र,  प...   \n",
       "\n",
       "                                                 tag  \n",
       "0  [<CD>, <JJ>, <NNP>, <NNP>, <NNP>, <CD>, <POP>,...  \n",
       "1  [<NN>, <NNP>, <NNP>, <NN>, <NN>, <NNP>, <FB>, ...  \n",
       "2  [<NNP>, <NN>, <NN>, <NNP>, <PKO>, <JJ>, <NN>, ...  \n",
       "3  [<RBO>, <NNP>, <NN>, <PKO>, <NN>, <VBI>, <NN>,...  \n",
       "4  [<DUM>, <POP>, <PKO>, <JJM>, <NN>, <POP>, <RP>...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['len_txt'] =data_df['text'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['len_tag'] =data_df['tag'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>len_txt</th>\n",
       "      <th>len_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, tag, len_txt, len_tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df['len_txt']!=data_df['len_tag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hence from the operation, we figure out that there is not mismatch between tags and text tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>len_txt</th>\n",
       "      <th>len_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[६१,  वर्षीय,  पियरे,  भिन्केन,  नोभेम्बर,  २९...</td>\n",
       "      <td>[&lt;CD&gt;, &lt;JJ&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;CD&gt;, &lt;POP&gt;,...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[श्री,  भिन्केन,  डच,  प्रकाशन,  समूह,  एल्सेभ...</td>\n",
       "      <td>[&lt;NN&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;NN&gt;, &lt;NN&gt;, &lt;NNP&gt;, &lt;FB&gt;, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[कन्सोलिडेटिड,  गोल्ड,  फिल्ड्स,  पीएलसी, का, ...</td>\n",
       "      <td>[&lt;NNP&gt;, &lt;NN&gt;, &lt;NN&gt;, &lt;NNP&gt;, &lt;PKO&gt;, &lt;JJ&gt;, &lt;NN&gt;, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[एकताका,  केन्ट,  चुरोट, को,  फिल्टर,  बनाउन, ...</td>\n",
       "      <td>[&lt;RBO&gt;, &lt;NNP&gt;, &lt;NN&gt;, &lt;PKO&gt;, &lt;NN&gt;, &lt;VBI&gt;, &lt;NN&gt;,...</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[यस, सँग, को,  छोटो,  सम्पर्क, बाट,  मात्र,  प...</td>\n",
       "      <td>[&lt;DUM&gt;, &lt;POP&gt;, &lt;PKO&gt;, &lt;JJM&gt;, &lt;NN&gt;, &lt;POP&gt;, &lt;RP&gt;...</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [६१,  वर्षीय,  पियरे,  भिन्केन,  नोभेम्बर,  २९...   \n",
       "1  [श्री,  भिन्केन,  डच,  प्रकाशन,  समूह,  एल्सेभ...   \n",
       "2  [कन्सोलिडेटिड,  गोल्ड,  फिल्ड्स,  पीएलसी, का, ...   \n",
       "3  [एकताका,  केन्ट,  चुरोट, को,  फिल्टर,  बनाउन, ...   \n",
       "4  [यस, सँग, को,  छोटो,  सम्पर्क, बाट,  मात्र,  प...   \n",
       "\n",
       "                                                 tag  len_txt  len_tag  \n",
       "0  [<CD>, <JJ>, <NNP>, <NNP>, <NNP>, <CD>, <POP>,...       16       16  \n",
       "1  [<NN>, <NNP>, <NNP>, <NN>, <NN>, <NNP>, <FB>, ...       11       11  \n",
       "2  [<NNP>, <NN>, <NN>, <NNP>, <PKO>, <JJ>, <NN>, ...       25       25  \n",
       "3  [<RBO>, <NNP>, <NN>, <PKO>, <NN>, <VBI>, <NN>,...       43       43  \n",
       "4  [<DUM>, <POP>, <PKO>, <JJM>, <NN>, <POP>, <RP>...       38       38  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['text'] = data_df['text'].apply(lambda x : [\"\".join(item.split(\" \")) for item in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Unicode value into ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['ascii_text'] = data_df['text'].apply(lambda x : [unicode_to_ascii(item) for item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns=['text','len_txt','len_tag'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[['ascii_text','tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ascii_text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[६१, वरषीय, पियर, भिनकन, नोभमबर, २९, बाट, सलला...</td>\n",
       "      <td>[&lt;CD&gt;, &lt;JJ&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;CD&gt;, &lt;POP&gt;,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[शरी, भिनकन, डच, परकाशन, समह, एलसभियर, एन.भी.,...</td>\n",
       "      <td>[&lt;NN&gt;, &lt;NNP&gt;, &lt;NNP&gt;, &lt;NN&gt;, &lt;NN&gt;, &lt;NNP&gt;, &lt;FB&gt;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[कनसोलिडटिड, गोलड, फिलडस, पीएलसी, का, परव, सभा...</td>\n",
       "      <td>[&lt;NNP&gt;, &lt;NN&gt;, &lt;NN&gt;, &lt;NNP&gt;, &lt;PKO&gt;, &lt;JJ&gt;, &lt;NN&gt;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[एकताका, कनट, चरोट, को, फिलटर, बनाउन, परयोग, भ...</td>\n",
       "      <td>[&lt;RBO&gt;, &lt;NNP&gt;, &lt;NN&gt;, &lt;PKO&gt;, &lt;NN&gt;, &lt;VBI&gt;, &lt;NN&gt;,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[यस, सग, को, छोटो, समपरक, बाट, मातर, पनि, दशकौ...</td>\n",
       "      <td>[&lt;DUM&gt;, &lt;POP&gt;, &lt;PKO&gt;, &lt;JJM&gt;, &lt;NN&gt;, &lt;POP&gt;, &lt;RP&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ascii_text  \\\n",
       "0  [६१, वरषीय, पियर, भिनकन, नोभमबर, २९, बाट, सलला...   \n",
       "1  [शरी, भिनकन, डच, परकाशन, समह, एलसभियर, एन.भी.,...   \n",
       "2  [कनसोलिडटिड, गोलड, फिलडस, पीएलसी, का, परव, सभा...   \n",
       "3  [एकताका, कनट, चरोट, को, फिलटर, बनाउन, परयोग, भ...   \n",
       "4  [यस, सग, को, छोटो, समपरक, बाट, मातर, पनि, दशकौ...   \n",
       "\n",
       "                                                 tag  \n",
       "0  [<CD>, <JJ>, <NNP>, <NNP>, <NNP>, <CD>, <POP>,...  \n",
       "1  [<NN>, <NNP>, <NNP>, <NN>, <NN>, <NNP>, <FB>, ...  \n",
       "2  [<NNP>, <NN>, <NN>, <NNP>, <PKO>, <JJ>, <NN>, ...  \n",
       "3  [<RBO>, <NNP>, <NN>, <PKO>, <NN>, <VBI>, <NN>,...  \n",
       "4  [<DUM>, <POP>, <PKO>, <JJM>, <NN>, <POP>, <RP>...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec and vec2word conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dictonary = list(set(sum(data_df['ascii_text'].tolist(),[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'परमपरा', 'ओगटन', 'रोव', 'परशासनिक', 'लखका', '३५', 'तयही']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dictonary[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dictionary = list(set(sum(data_df['tag'].tolist(),[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<ALPH>', '<NNP>', '<VBX>', '<DM>', '<UNW>', '<VBNE>', '<FB>', '<PLE>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_dictionary[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2word = dict(enumerate(word_dictonary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {int2word[idx]:idx for idx in int2word.keys() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2tag = dict(enumerate(tag_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2int = {int2tag[idx]:idx for idx in int2tag.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_num = round((1-SPLIT_RATIO)*data_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ascii_text    0\n",
       "tag           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_df[:split_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = data_df[split_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3434, 2), (858, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape,valid_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POS_Tagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.6,inplace=True)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        drop_out_tag = self.dropout(tag_space)\n",
    "        tag_scores = self.log_softmax(drop_out_tag)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(word_dictonary)\n",
    "OUTPUT_DIM = len(tag_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11993, 39)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM,OUTPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = POS_Tagger(EMBEDDING_DIM, HIDDEN_DIM, INPUT_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POS_Tagger(\n",
       "  (word_embeddings): Embedding(11993, 300)\n",
       "  (lstm): LSTM(300, 150)\n",
       "  (hidden2tag): Linear(in_features=150, out_features=39, bias=True)\n",
       "  (log_softmax): LogSoftmax()\n",
       "  (dropout): Dropout(p=0.6, inplace)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initailization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "EPOCHS = 20\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss, Optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = list(train_dataset.itertuples(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = list(valid_dataset.itertuples(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20............. Training Loss: 0.00 Validation Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "epoch_loss_train=[]\n",
    "epoch_loss_valid=[]\n",
    "acc_score_list=[]\n",
    "for epoch in range(EPOCHS):\n",
    "    net_loss_train = 0\n",
    "    train_len=0.001\n",
    "    for sentence, tags in train_dataset:\n",
    "        # Get our inputs ready for the network, that is, turn them into\n",
    "        sent_int = prepare_sequence(sentence, word2int)\n",
    "        tag_int = prepare_sequence(tags, tag2int)\n",
    "        # Run our forward pass.\n",
    "        try:\n",
    "            tag_scores = model(sent_int)\n",
    "            # Compute the loss, gradients, and update the parameters \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(tag_scores, tag_int)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            net_loss_train+=loss.item()\n",
    "            train_len+=1\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        # cross validation\n",
    "        with torch.no_grad():\n",
    "            net_loss_valid=0\n",
    "            valid_len=0.001\n",
    "            acc_score=0\n",
    "            for sentence,tags in valid_dataset:\n",
    "                sent_int = prepare_sequence(sentence,word2int)\n",
    "                tag_int = prepare_sequence(tags,tag2int)\n",
    "                #Step 3. Run our forward pass.\n",
    "                try:\n",
    "                    tag_scores = model(sent_int)\n",
    "\n",
    "                    # Step 4. Compute the loss \n",
    "                    net_loss_valid+=criterion(tag_scores, tag_int).item()\n",
    "                    valid_len+=1\n",
    "                    true_value = tag_int.tolist()\n",
    "                    predicted_value=[]\n",
    "                    for item in score:\n",
    "                        predicted_value.append(torch.argmax(item))\n",
    "                    predicted_value = torch.IntTensor(predicted_value).tolist()\n",
    "                    acc_score+=acc_scaccuracy_score(true_val,predicted_value)\n",
    "                    \n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "    epoch_loss_train.append(net_loss_train/train_len)\n",
    "    epoch_loss_valid.append(net_loss_valid/valid_len)\n",
    "    acc_score_list.append(acc_score/valid_len)\n",
    "    torch.save(model.state_dict(),'../model/POS_Tagger_model_epoch'+str(epoch))\n",
    "    if (epoch+1)%2 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, EPOCHS), end=' ')\n",
    "        print(\"Training Loss: {:.2f}\".format(net_loss_train/train_len),end=' ')\n",
    "        print(\"Validation Loss: {:.2f}\".format(net_loss_valid/valid_len),end=' ')\n",
    "        print(\"Accuracy Score: {:.2f}\".format(acc_score/valid_len),end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
